{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Blaine Hill\n",
    "\n",
    "In this notebook, we program out how to embed a KG such as FB15k_237 using RotatE. The weights are saved under embedding_model_weights.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"embedding_model.ipynb\"\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from torch_geometric.nn import RotatE\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from torch_geometric.nn import ComplEx\n",
    "\n",
    "dataset_name='FB15k_237'\n",
    "embedding_model_name='RotatE'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = osp.join(os.getcwd(), '..', 'data', dataset_name)\n",
    "\n",
    "train_data = FB15k_237(path, split='train')[0].to(device)\n",
    "val_data = FB15k_237(path, split='val')[0].to(device)\n",
    "test_data = FB15k_237(path, split='test')[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/blaineh2/ScoreMatchingDiffKG/embedding_model/wandb/run-20240227_031104-yhrxb62j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/yhrxb62j' target=\"_blank\">FB15k_237_RotatE_embedding_model 2024-02-27 03:11:04</a></strong> to <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding' target=\"_blank\">https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/yhrxb62j' target=\"_blank\">https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/yhrxb62j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=f\"ScoreMatchingDiffKG_Embedding\",\n",
    "    name=f\"{dataset_name}_{embedding_model_name}_embedding_model {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    config={\n",
    "        \"epochs\": 500,\n",
    "        \"batch_size\": 1000,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"k\": 10 #used for top-k evaluation\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RotatE(num_nodes=train_data.num_nodes, num_relations=train_data.num_edge_types, hidden_channels=50).to(device) \n",
    "\n",
    "wandb.watch(model) #tracks gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on FB15k dataset\n",
    "train_loader = model.loader(\n",
    "    head_index=train_data.edge_index[0],\n",
    "    rel_type=train_data.edge_type,\n",
    "    tail_index=train_data.edge_index[1],\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "# val_loader = model.loader(\n",
    "#     head_index=val_data.edge_index[0],\n",
    "#     rel_type=val_data.edge_type,\n",
    "#     tail_index=val_data.edge_index[1],\n",
    "#     batch_size=config.batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "# test_loader = model.loader(\n",
    "#     head_index=test_data.edge_index[0],\n",
    "#     rel_type=test_data.edge_type,\n",
    "#     tail_index=test_data.edge_index[1],\n",
    "#     batch_size=config.batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for head_index, rel_type, tail_index in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(head_index, rel_type, tail_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scale on specific number of elements in batch\n",
    "        total_loss += float(loss) * head_index.numel()\n",
    "        total_examples += head_index.numel()\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    # Calculate loss\n",
    "    loss = model.loss(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "    )\n",
    "    # Evaluate the model using model.test()\n",
    "    mean_rank, mrr, hits_at_k = model.test(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "        batch_size=config.batch_size,\n",
    "        k=config.k,\n",
    "    )\n",
    "    return loss, mean_rank, mrr, hits_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.7774\n",
      "Epoch: 002, Train Loss: 0.7709\n",
      "Epoch: 003, Train Loss: 0.7668\n",
      "Epoch: 004, Train Loss: 0.7635\n",
      "Epoch: 005, Train Loss: 0.7608\n",
      "Epoch: 006, Train Loss: 0.7584\n",
      "Epoch: 007, Train Loss: 0.7562\n",
      "Epoch: 008, Train Loss: 0.7542\n",
      "Epoch: 009, Train Loss: 0.7524\n",
      "Epoch: 010, Train Loss: 0.7507\n",
      "Epoch: 011, Train Loss: 0.7491\n",
      "Epoch: 012, Train Loss: 0.7477\n",
      "Epoch: 013, Train Loss: 0.7462\n",
      "Epoch: 014, Train Loss: 0.7449\n",
      "Epoch: 015, Train Loss: 0.7436\n",
      "Epoch: 016, Train Loss: 0.7423\n",
      "Epoch: 017, Train Loss: 0.7411\n",
      "Epoch: 018, Train Loss: 0.7400\n",
      "Epoch: 019, Train Loss: 0.7388\n",
      "Epoch: 020, Train Loss: 0.7378\n",
      "Epoch: 021, Train Loss: 0.7367\n",
      "Epoch: 022, Train Loss: 0.7357\n",
      "Epoch: 023, Train Loss: 0.7348\n",
      "Epoch: 024, Train Loss: 0.7338\n",
      "Epoch: 025, Train Loss: 0.7329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:08<00:00, 70.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 4517.82, Val Mean Reciprocal Rank: 0.00, Val Hits@10: 0.0018\n",
      "Epoch: 026, Train Loss: 0.7320\n",
      "Epoch: 027, Train Loss: 0.7310\n",
      "Epoch: 028, Train Loss: 0.7302\n",
      "Epoch: 029, Train Loss: 0.7294\n",
      "Epoch: 030, Train Loss: 0.7286\n",
      "Epoch: 031, Train Loss: 0.7278\n",
      "Epoch: 032, Train Loss: 0.7269\n",
      "Epoch: 033, Train Loss: 0.7262\n",
      "Epoch: 034, Train Loss: 0.7254\n",
      "Epoch: 035, Train Loss: 0.7247\n",
      "Epoch: 036, Train Loss: 0.7240\n",
      "Epoch: 037, Train Loss: 0.7233\n",
      "Epoch: 038, Train Loss: 0.7225\n",
      "Epoch: 039, Train Loss: 0.7219\n",
      "Epoch: 040, Train Loss: 0.7212\n",
      "Epoch: 041, Train Loss: 0.7205\n",
      "Epoch: 042, Train Loss: 0.7198\n",
      "Epoch: 043, Train Loss: 0.7192\n",
      "Epoch: 044, Train Loss: 0.7186\n",
      "Epoch: 045, Train Loss: 0.7179\n",
      "Epoch: 046, Train Loss: 0.7173\n",
      "Epoch: 047, Train Loss: 0.7166\n",
      "Epoch: 048, Train Loss: 0.7161\n",
      "Epoch: 049, Train Loss: 0.7155\n",
      "Epoch: 050, Train Loss: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:07<00:00, 70.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 3340.89, Val Mean Reciprocal Rank: 0.02, Val Hits@10: 0.0376\n",
      "Epoch: 051, Train Loss: 0.7143\n",
      "Epoch: 052, Train Loss: 0.7137\n",
      "Epoch: 053, Train Loss: 0.7132\n",
      "Epoch: 054, Train Loss: 0.7126\n",
      "Epoch: 055, Train Loss: 0.7121\n",
      "Epoch: 056, Train Loss: 0.7116\n",
      "Epoch: 057, Train Loss: 0.7110\n",
      "Epoch: 058, Train Loss: 0.7104\n",
      "Epoch: 059, Train Loss: 0.7100\n",
      "Epoch: 060, Train Loss: 0.7094\n",
      "Epoch: 061, Train Loss: 0.7089\n",
      "Epoch: 062, Train Loss: 0.7085\n",
      "Epoch: 063, Train Loss: 0.7080\n",
      "Epoch: 064, Train Loss: 0.7074\n",
      "Epoch: 065, Train Loss: 0.7069\n",
      "Epoch: 066, Train Loss: 0.7065\n",
      "Epoch: 067, Train Loss: 0.7059\n",
      "Epoch: 068, Train Loss: 0.7055\n",
      "Epoch: 069, Train Loss: 0.7050\n",
      "Epoch: 070, Train Loss: 0.7046\n",
      "Epoch: 071, Train Loss: 0.7041\n",
      "Epoch: 072, Train Loss: 0.7036\n",
      "Epoch: 073, Train Loss: 0.7032\n",
      "Epoch: 074, Train Loss: 0.7028\n",
      "Epoch: 075, Train Loss: 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:00<00:00, 72.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2981.51, Val Mean Reciprocal Rank: 0.03, Val Hits@10: 0.0676\n",
      "Epoch: 076, Train Loss: 0.7019\n",
      "Epoch: 077, Train Loss: 0.7014\n",
      "Epoch: 078, Train Loss: 0.7010\n",
      "Epoch: 079, Train Loss: 0.7006\n",
      "Epoch: 080, Train Loss: 0.7001\n",
      "Epoch: 081, Train Loss: 0.6997\n",
      "Epoch: 082, Train Loss: 0.6993\n",
      "Epoch: 083, Train Loss: 0.6988\n",
      "Epoch: 084, Train Loss: 0.6984\n",
      "Epoch: 085, Train Loss: 0.6980\n",
      "Epoch: 086, Train Loss: 0.6977\n",
      "Epoch: 087, Train Loss: 0.6972\n",
      "Epoch: 088, Train Loss: 0.6968\n",
      "Epoch: 089, Train Loss: 0.6964\n",
      "Epoch: 090, Train Loss: 0.6960\n",
      "Epoch: 091, Train Loss: 0.6956\n",
      "Epoch: 092, Train Loss: 0.6953\n",
      "Epoch: 093, Train Loss: 0.6949\n",
      "Epoch: 094, Train Loss: 0.6945\n",
      "Epoch: 095, Train Loss: 0.6941\n",
      "Epoch: 096, Train Loss: 0.6937\n",
      "Epoch: 097, Train Loss: 0.6934\n",
      "Epoch: 098, Train Loss: 0.6930\n",
      "Epoch: 099, Train Loss: 0.6927\n",
      "Epoch: 100, Train Loss: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:10<00:00, 69.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2799.25, Val Mean Reciprocal Rank: 0.04, Val Hits@10: 0.0813\n",
      "Epoch: 101, Train Loss: 0.6919\n",
      "Epoch: 102, Train Loss: 0.6916\n",
      "Epoch: 103, Train Loss: 0.6912\n",
      "Epoch: 104, Train Loss: 0.6908\n",
      "Epoch: 105, Train Loss: 0.6906\n",
      "Epoch: 106, Train Loss: 0.6901\n",
      "Epoch: 107, Train Loss: 0.6898\n",
      "Epoch: 108, Train Loss: 0.6894\n",
      "Epoch: 109, Train Loss: 0.6891\n",
      "Epoch: 110, Train Loss: 0.6888\n",
      "Epoch: 111, Train Loss: 0.6884\n",
      "Epoch: 112, Train Loss: 0.6882\n",
      "Epoch: 113, Train Loss: 0.6877\n",
      "Epoch: 114, Train Loss: 0.6875\n",
      "Epoch: 115, Train Loss: 0.6871\n",
      "Epoch: 116, Train Loss: 0.6868\n",
      "Epoch: 117, Train Loss: 0.6865\n",
      "Epoch: 118, Train Loss: 0.6861\n",
      "Epoch: 119, Train Loss: 0.6859\n",
      "Epoch: 120, Train Loss: 0.6854\n",
      "Epoch: 121, Train Loss: 0.6852\n",
      "Epoch: 122, Train Loss: 0.6849\n",
      "Epoch: 123, Train Loss: 0.6846\n",
      "Epoch: 124, Train Loss: 0.6843\n",
      "Epoch: 125, Train Loss: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:00<00:00, 73.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2682.05, Val Mean Reciprocal Rank: 0.04, Val Hits@10: 0.0902\n",
      "Epoch: 126, Train Loss: 0.6836\n",
      "Epoch: 127, Train Loss: 0.6833\n",
      "Epoch: 128, Train Loss: 0.6829\n",
      "Epoch: 129, Train Loss: 0.6827\n",
      "Epoch: 130, Train Loss: 0.6826\n",
      "Epoch: 131, Train Loss: 0.6821\n",
      "Epoch: 132, Train Loss: 0.6818\n",
      "Epoch: 133, Train Loss: 0.6815\n",
      "Epoch: 134, Train Loss: 0.6813\n",
      "Epoch: 135, Train Loss: 0.6809\n",
      "Epoch: 136, Train Loss: 0.6806\n",
      "Epoch: 137, Train Loss: 0.6803\n",
      "Epoch: 138, Train Loss: 0.6801\n",
      "Epoch: 139, Train Loss: 0.6798\n",
      "Epoch: 140, Train Loss: 0.6794\n",
      "Epoch: 141, Train Loss: 0.6793\n",
      "Epoch: 142, Train Loss: 0.6789\n",
      "Epoch: 143, Train Loss: 0.6785\n",
      "Epoch: 144, Train Loss: 0.6783\n",
      "Epoch: 145, Train Loss: 0.6780\n",
      "Epoch: 146, Train Loss: 0.6778\n",
      "Epoch: 147, Train Loss: 0.6774\n",
      "Epoch: 148, Train Loss: 0.6773\n",
      "Epoch: 149, Train Loss: 0.6770\n",
      "Epoch: 150, Train Loss: 0.6767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:03<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2596.45, Val Mean Reciprocal Rank: 0.05, Val Hits@10: 0.1003\n",
      "Epoch: 151, Train Loss: 0.6764\n",
      "Epoch: 152, Train Loss: 0.6762\n",
      "Epoch: 153, Train Loss: 0.6758\n",
      "Epoch: 154, Train Loss: 0.6755\n",
      "Epoch: 155, Train Loss: 0.6754\n",
      "Epoch: 156, Train Loss: 0.6751\n",
      "Epoch: 157, Train Loss: 0.6748\n",
      "Epoch: 158, Train Loss: 0.6746\n",
      "Epoch: 159, Train Loss: 0.6743\n",
      "Epoch: 160, Train Loss: 0.6739\n",
      "Epoch: 161, Train Loss: 0.6736\n",
      "Epoch: 162, Train Loss: 0.6735\n",
      "Epoch: 163, Train Loss: 0.6731\n",
      "Epoch: 164, Train Loss: 0.6731\n",
      "Epoch: 165, Train Loss: 0.6726\n",
      "Epoch: 166, Train Loss: 0.6724\n",
      "Epoch: 167, Train Loss: 0.6721\n",
      "Epoch: 168, Train Loss: 0.6721\n",
      "Epoch: 169, Train Loss: 0.6715\n",
      "Epoch: 170, Train Loss: 0.6714\n",
      "Epoch: 171, Train Loss: 0.6714\n",
      "Epoch: 172, Train Loss: 0.6710\n",
      "Epoch: 173, Train Loss: 0.6708\n",
      "Epoch: 174, Train Loss: 0.6705\n",
      "Epoch: 175, Train Loss: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:14<00:00, 69.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2526.99, Val Mean Reciprocal Rank: 0.05, Val Hits@10: 0.1081\n",
      "Epoch: 176, Train Loss: 0.6700\n",
      "Epoch: 177, Train Loss: 0.6698\n",
      "Epoch: 178, Train Loss: 0.6695\n",
      "Epoch: 179, Train Loss: 0.6693\n",
      "Epoch: 180, Train Loss: 0.6691\n",
      "Epoch: 181, Train Loss: 0.6688\n",
      "Epoch: 182, Train Loss: 0.6686\n",
      "Epoch: 183, Train Loss: 0.6684\n",
      "Epoch: 184, Train Loss: 0.6680\n",
      "Epoch: 185, Train Loss: 0.6679\n",
      "Epoch: 186, Train Loss: 0.6676\n",
      "Epoch: 187, Train Loss: 0.6675\n",
      "Epoch: 188, Train Loss: 0.6672\n",
      "Epoch: 189, Train Loss: 0.6670\n",
      "Epoch: 190, Train Loss: 0.6669\n",
      "Epoch: 191, Train Loss: 0.6665\n",
      "Epoch: 192, Train Loss: 0.6663\n",
      "Epoch: 193, Train Loss: 0.6662\n",
      "Epoch: 194, Train Loss: 0.6659\n",
      "Epoch: 195, Train Loss: 0.6655\n",
      "Epoch: 196, Train Loss: 0.6653\n",
      "Epoch: 197, Train Loss: 0.6651\n",
      "Epoch: 198, Train Loss: 0.6650\n",
      "Epoch: 199, Train Loss: 0.6648\n",
      "Epoch: 200, Train Loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:02<00:00, 72.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2468.34, Val Mean Reciprocal Rank: 0.06, Val Hits@10: 0.1151\n",
      "Epoch: 201, Train Loss: 0.6643\n",
      "Epoch: 202, Train Loss: 0.6641\n",
      "Epoch: 203, Train Loss: 0.6638\n",
      "Epoch: 204, Train Loss: 0.6635\n",
      "Epoch: 205, Train Loss: 0.6634\n",
      "Epoch: 206, Train Loss: 0.6633\n",
      "Epoch: 207, Train Loss: 0.6629\n",
      "Epoch: 208, Train Loss: 0.6628\n",
      "Epoch: 209, Train Loss: 0.6625\n",
      "Epoch: 210, Train Loss: 0.6624\n",
      "Epoch: 211, Train Loss: 0.6621\n",
      "Epoch: 212, Train Loss: 0.6619\n",
      "Epoch: 213, Train Loss: 0.6616\n",
      "Epoch: 214, Train Loss: 0.6616\n",
      "Epoch: 215, Train Loss: 0.6613\n",
      "Epoch: 216, Train Loss: 0.6610\n",
      "Epoch: 217, Train Loss: 0.6610\n",
      "Epoch: 218, Train Loss: 0.6606\n",
      "Epoch: 219, Train Loss: 0.6605\n",
      "Epoch: 220, Train Loss: 0.6602\n",
      "Epoch: 221, Train Loss: 0.6600\n",
      "Epoch: 222, Train Loss: 0.6600\n",
      "Epoch: 223, Train Loss: 0.6598\n",
      "Epoch: 224, Train Loss: 0.6595\n",
      "Epoch: 225, Train Loss: 0.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:16<00:00, 68.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2416.84, Val Mean Reciprocal Rank: 0.06, Val Hits@10: 0.1217\n",
      "Epoch: 226, Train Loss: 0.6590\n",
      "Epoch: 227, Train Loss: 0.6588\n",
      "Epoch: 228, Train Loss: 0.6587\n",
      "Epoch: 229, Train Loss: 0.6584\n",
      "Epoch: 230, Train Loss: 0.6584\n",
      "Epoch: 231, Train Loss: 0.6580\n",
      "Epoch: 232, Train Loss: 0.6580\n",
      "Epoch: 233, Train Loss: 0.6577\n",
      "Epoch: 234, Train Loss: 0.6574\n",
      "Epoch: 235, Train Loss: 0.6573\n",
      "Epoch: 236, Train Loss: 0.6571\n",
      "Epoch: 237, Train Loss: 0.6569\n",
      "Epoch: 238, Train Loss: 0.6567\n",
      "Epoch: 239, Train Loss: 0.6564\n",
      "Epoch: 240, Train Loss: 0.6563\n",
      "Epoch: 241, Train Loss: 0.6560\n",
      "Epoch: 242, Train Loss: 0.6559\n",
      "Epoch: 243, Train Loss: 0.6558\n",
      "Epoch: 244, Train Loss: 0.6555\n",
      "Epoch: 245, Train Loss: 0.6555\n",
      "Epoch: 246, Train Loss: 0.6552\n",
      "Epoch: 247, Train Loss: 0.6549\n",
      "Epoch: 248, Train Loss: 0.6548\n",
      "Epoch: 249, Train Loss: 0.6547\n",
      "Epoch: 250, Train Loss: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:07<00:00, 70.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2370.21, Val Mean Reciprocal Rank: 0.06, Val Hits@10: 0.1276\n",
      "Epoch: 251, Train Loss: 0.6543\n",
      "Epoch: 252, Train Loss: 0.6541\n",
      "Epoch: 253, Train Loss: 0.6540\n",
      "Epoch: 254, Train Loss: 0.6536\n",
      "Epoch: 255, Train Loss: 0.6536\n",
      "Epoch: 256, Train Loss: 0.6533\n",
      "Epoch: 257, Train Loss: 0.6532\n",
      "Epoch: 258, Train Loss: 0.6531\n",
      "Epoch: 259, Train Loss: 0.6529\n",
      "Epoch: 260, Train Loss: 0.6526\n",
      "Epoch: 261, Train Loss: 0.6524\n",
      "Epoch: 262, Train Loss: 0.6522\n",
      "Epoch: 263, Train Loss: 0.6521\n",
      "Epoch: 264, Train Loss: 0.6519\n",
      "Epoch: 265, Train Loss: 0.6519\n",
      "Epoch: 266, Train Loss: 0.6516\n",
      "Epoch: 267, Train Loss: 0.6514\n",
      "Epoch: 268, Train Loss: 0.6513\n",
      "Epoch: 269, Train Loss: 0.6511\n",
      "Epoch: 270, Train Loss: 0.6509\n",
      "Epoch: 271, Train Loss: 0.6505\n",
      "Epoch: 272, Train Loss: 0.6505\n",
      "Epoch: 273, Train Loss: 0.6505\n",
      "Epoch: 274, Train Loss: 0.6503\n",
      "Epoch: 275, Train Loss: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:11<00:00, 69.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2326.99, Val Mean Reciprocal Rank: 0.07, Val Hits@10: 0.1317\n",
      "Epoch: 276, Train Loss: 0.6498\n",
      "Epoch: 277, Train Loss: 0.6496\n",
      "Epoch: 278, Train Loss: 0.6494\n",
      "Epoch: 279, Train Loss: 0.6494\n",
      "Epoch: 280, Train Loss: 0.6492\n",
      "Epoch: 281, Train Loss: 0.6491\n",
      "Epoch: 282, Train Loss: 0.6489\n",
      "Epoch: 283, Train Loss: 0.6487\n",
      "Epoch: 284, Train Loss: 0.6485\n",
      "Epoch: 285, Train Loss: 0.6483\n",
      "Epoch: 286, Train Loss: 0.6481\n",
      "Epoch: 287, Train Loss: 0.6480\n",
      "Epoch: 288, Train Loss: 0.6479\n",
      "Epoch: 289, Train Loss: 0.6475\n",
      "Epoch: 290, Train Loss: 0.6474\n",
      "Epoch: 291, Train Loss: 0.6474\n",
      "Epoch: 292, Train Loss: 0.6471\n",
      "Epoch: 293, Train Loss: 0.6471\n",
      "Epoch: 294, Train Loss: 0.6468\n",
      "Epoch: 295, Train Loss: 0.6467\n",
      "Epoch: 296, Train Loss: 0.6465\n",
      "Epoch: 297, Train Loss: 0.6463\n",
      "Epoch: 298, Train Loss: 0.6460\n",
      "Epoch: 299, Train Loss: 0.6460\n",
      "Epoch: 300, Train Loss: 0.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [03:56<00:00, 74.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2286.27, Val Mean Reciprocal Rank: 0.07, Val Hits@10: 0.1349\n",
      "Epoch: 301, Train Loss: 0.6456\n",
      "Epoch: 302, Train Loss: 0.6454\n",
      "Epoch: 303, Train Loss: 0.6454\n",
      "Epoch: 304, Train Loss: 0.6452\n",
      "Epoch: 305, Train Loss: 0.6450\n",
      "Epoch: 306, Train Loss: 0.6449\n",
      "Epoch: 307, Train Loss: 0.6447\n",
      "Epoch: 308, Train Loss: 0.6447\n",
      "Epoch: 309, Train Loss: 0.6443\n",
      "Epoch: 310, Train Loss: 0.6444\n",
      "Epoch: 311, Train Loss: 0.6442\n",
      "Epoch: 312, Train Loss: 0.6441\n",
      "Epoch: 313, Train Loss: 0.6438\n",
      "Epoch: 314, Train Loss: 0.6438\n",
      "Epoch: 315, Train Loss: 0.6434\n",
      "Epoch: 316, Train Loss: 0.6434\n",
      "Epoch: 317, Train Loss: 0.6432\n",
      "Epoch: 318, Train Loss: 0.6432\n",
      "Epoch: 319, Train Loss: 0.6429\n",
      "Epoch: 320, Train Loss: 0.6426\n",
      "Epoch: 321, Train Loss: 0.6426\n",
      "Epoch: 322, Train Loss: 0.6426\n",
      "Epoch: 323, Train Loss: 0.6424\n",
      "Epoch: 324, Train Loss: 0.6421\n",
      "Epoch: 325, Train Loss: 0.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:08<00:00, 70.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2248.36, Val Mean Reciprocal Rank: 0.07, Val Hits@10: 0.1418\n",
      "Epoch: 326, Train Loss: 0.6418\n",
      "Epoch: 327, Train Loss: 0.6417\n",
      "Epoch: 328, Train Loss: 0.6416\n",
      "Epoch: 329, Train Loss: 0.6414\n",
      "Epoch: 330, Train Loss: 0.6412\n",
      "Epoch: 331, Train Loss: 0.6411\n",
      "Epoch: 332, Train Loss: 0.6409\n",
      "Epoch: 333, Train Loss: 0.6408\n",
      "Epoch: 334, Train Loss: 0.6407\n",
      "Epoch: 335, Train Loss: 0.6407\n",
      "Epoch: 336, Train Loss: 0.6405\n",
      "Epoch: 337, Train Loss: 0.6403\n",
      "Epoch: 338, Train Loss: 0.6403\n",
      "Epoch: 339, Train Loss: 0.6400\n",
      "Epoch: 340, Train Loss: 0.6400\n",
      "Epoch: 341, Train Loss: 0.6397\n",
      "Epoch: 342, Train Loss: 0.6394\n",
      "Epoch: 343, Train Loss: 0.6394\n",
      "Epoch: 344, Train Loss: 0.6392\n",
      "Epoch: 345, Train Loss: 0.6391\n",
      "Epoch: 346, Train Loss: 0.6390\n",
      "Epoch: 347, Train Loss: 0.6388\n",
      "Epoch: 348, Train Loss: 0.6386\n",
      "Epoch: 349, Train Loss: 0.6385\n",
      "Epoch: 350, Train Loss: 0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:06<00:00, 71.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2212.24, Val Mean Reciprocal Rank: 0.07, Val Hits@10: 0.1468\n",
      "Epoch: 351, Train Loss: 0.6383\n",
      "Epoch: 352, Train Loss: 0.6382\n",
      "Epoch: 353, Train Loss: 0.6380\n",
      "Epoch: 354, Train Loss: 0.6378\n",
      "Epoch: 355, Train Loss: 0.6378\n",
      "Epoch: 356, Train Loss: 0.6376\n",
      "Epoch: 357, Train Loss: 0.6374\n",
      "Epoch: 358, Train Loss: 0.6374\n",
      "Epoch: 359, Train Loss: 0.6371\n",
      "Epoch: 360, Train Loss: 0.6371\n",
      "Epoch: 361, Train Loss: 0.6368\n",
      "Epoch: 362, Train Loss: 0.6365\n",
      "Epoch: 363, Train Loss: 0.6367\n",
      "Epoch: 364, Train Loss: 0.6365\n",
      "Epoch: 365, Train Loss: 0.6362\n",
      "Epoch: 366, Train Loss: 0.6363\n",
      "Epoch: 367, Train Loss: 0.6360\n",
      "Epoch: 368, Train Loss: 0.6361\n",
      "Epoch: 369, Train Loss: 0.6357\n",
      "Epoch: 370, Train Loss: 0.6358\n",
      "Epoch: 371, Train Loss: 0.6354\n",
      "Epoch: 372, Train Loss: 0.6353\n",
      "Epoch: 373, Train Loss: 0.6353\n",
      "Epoch: 374, Train Loss: 0.6352\n",
      "Epoch: 375, Train Loss: 0.6350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:06<00:00, 71.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2177.77, Val Mean Reciprocal Rank: 0.08, Val Hits@10: 0.1526\n",
      "Epoch: 376, Train Loss: 0.6348\n",
      "Epoch: 377, Train Loss: 0.6349\n",
      "Epoch: 378, Train Loss: 0.6344\n",
      "Epoch: 379, Train Loss: 0.6344\n",
      "Epoch: 380, Train Loss: 0.6343\n",
      "Epoch: 381, Train Loss: 0.6341\n",
      "Epoch: 382, Train Loss: 0.6340\n",
      "Epoch: 383, Train Loss: 0.6339\n",
      "Epoch: 384, Train Loss: 0.6337\n",
      "Epoch: 385, Train Loss: 0.6336\n",
      "Epoch: 386, Train Loss: 0.6336\n",
      "Epoch: 387, Train Loss: 0.6334\n",
      "Epoch: 388, Train Loss: 0.6332\n",
      "Epoch: 389, Train Loss: 0.6332\n",
      "Epoch: 390, Train Loss: 0.6331\n",
      "Epoch: 391, Train Loss: 0.6329\n",
      "Epoch: 392, Train Loss: 0.6330\n",
      "Epoch: 393, Train Loss: 0.6327\n",
      "Epoch: 394, Train Loss: 0.6326\n",
      "Epoch: 395, Train Loss: 0.6324\n",
      "Epoch: 396, Train Loss: 0.6323\n",
      "Epoch: 397, Train Loss: 0.6320\n",
      "Epoch: 398, Train Loss: 0.6318\n",
      "Epoch: 399, Train Loss: 0.6319\n",
      "Epoch: 400, Train Loss: 0.6317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [03:55<00:00, 74.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2144.64, Val Mean Reciprocal Rank: 0.08, Val Hits@10: 0.1581\n",
      "Epoch: 401, Train Loss: 0.6317\n",
      "Epoch: 402, Train Loss: 0.6316\n",
      "Epoch: 403, Train Loss: 0.6313\n",
      "Epoch: 404, Train Loss: 0.6312\n",
      "Epoch: 405, Train Loss: 0.6310\n",
      "Epoch: 406, Train Loss: 0.6307\n",
      "Epoch: 407, Train Loss: 0.6309\n",
      "Epoch: 408, Train Loss: 0.6306\n",
      "Epoch: 409, Train Loss: 0.6307\n",
      "Epoch: 410, Train Loss: 0.6305\n",
      "Epoch: 411, Train Loss: 0.6303\n",
      "Epoch: 412, Train Loss: 0.6302\n",
      "Epoch: 413, Train Loss: 0.6302\n",
      "Epoch: 414, Train Loss: 0.6300\n",
      "Epoch: 415, Train Loss: 0.6300\n",
      "Epoch: 416, Train Loss: 0.6296\n",
      "Epoch: 417, Train Loss: 0.6296\n",
      "Epoch: 418, Train Loss: 0.6294\n",
      "Epoch: 419, Train Loss: 0.6293\n",
      "Epoch: 420, Train Loss: 0.6294\n",
      "Epoch: 421, Train Loss: 0.6290\n",
      "Epoch: 422, Train Loss: 0.6290\n",
      "Epoch: 423, Train Loss: 0.6287\n",
      "Epoch: 424, Train Loss: 0.6288\n",
      "Epoch: 425, Train Loss: 0.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:00<00:00, 72.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2112.91, Val Mean Reciprocal Rank: 0.08, Val Hits@10: 0.1627\n",
      "Epoch: 426, Train Loss: 0.6285\n",
      "Epoch: 427, Train Loss: 0.6285\n",
      "Epoch: 428, Train Loss: 0.6282\n",
      "Epoch: 429, Train Loss: 0.6281\n",
      "Epoch: 430, Train Loss: 0.6279\n",
      "Epoch: 431, Train Loss: 0.6279\n",
      "Epoch: 432, Train Loss: 0.6279\n",
      "Epoch: 433, Train Loss: 0.6276\n",
      "Epoch: 434, Train Loss: 0.6276\n",
      "Epoch: 435, Train Loss: 0.6275\n",
      "Epoch: 436, Train Loss: 0.6272\n",
      "Epoch: 437, Train Loss: 0.6270\n",
      "Epoch: 438, Train Loss: 0.6271\n",
      "Epoch: 439, Train Loss: 0.6270\n",
      "Epoch: 440, Train Loss: 0.6267\n",
      "Epoch: 441, Train Loss: 0.6267\n",
      "Epoch: 442, Train Loss: 0.6268\n",
      "Epoch: 443, Train Loss: 0.6266\n",
      "Epoch: 444, Train Loss: 0.6266\n",
      "Epoch: 445, Train Loss: 0.6265\n",
      "Epoch: 446, Train Loss: 0.6261\n",
      "Epoch: 447, Train Loss: 0.6262\n",
      "Epoch: 448, Train Loss: 0.6259\n",
      "Epoch: 449, Train Loss: 0.6259\n",
      "Epoch: 450, Train Loss: 0.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [03:56<00:00, 74.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2082.62, Val Mean Reciprocal Rank: 0.09, Val Hits@10: 0.1661\n",
      "Epoch: 451, Train Loss: 0.6255\n",
      "Epoch: 452, Train Loss: 0.6254\n",
      "Epoch: 453, Train Loss: 0.6253\n",
      "Epoch: 454, Train Loss: 0.6253\n",
      "Epoch: 455, Train Loss: 0.6254\n",
      "Epoch: 456, Train Loss: 0.6249\n",
      "Epoch: 457, Train Loss: 0.6250\n",
      "Epoch: 458, Train Loss: 0.6249\n",
      "Epoch: 459, Train Loss: 0.6249\n",
      "Epoch: 460, Train Loss: 0.6246\n",
      "Epoch: 461, Train Loss: 0.6246\n",
      "Epoch: 462, Train Loss: 0.6243\n",
      "Epoch: 463, Train Loss: 0.6243\n",
      "Epoch: 464, Train Loss: 0.6242\n",
      "Epoch: 465, Train Loss: 0.6241\n",
      "Epoch: 466, Train Loss: 0.6241\n",
      "Epoch: 467, Train Loss: 0.6239\n",
      "Epoch: 468, Train Loss: 0.6237\n",
      "Epoch: 469, Train Loss: 0.6235\n",
      "Epoch: 470, Train Loss: 0.6234\n",
      "Epoch: 471, Train Loss: 0.6233\n",
      "Epoch: 472, Train Loss: 0.6234\n",
      "Epoch: 473, Train Loss: 0.6232\n",
      "Epoch: 474, Train Loss: 0.6227\n",
      "Epoch: 475, Train Loss: 0.6231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:03<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2053.02, Val Mean Reciprocal Rank: 0.09, Val Hits@10: 0.1706\n",
      "Epoch: 476, Train Loss: 0.6228\n",
      "Epoch: 477, Train Loss: 0.6229\n",
      "Epoch: 478, Train Loss: 0.6225\n",
      "Epoch: 479, Train Loss: 0.6223\n",
      "Epoch: 480, Train Loss: 0.6223\n",
      "Epoch: 481, Train Loss: 0.6223\n",
      "Epoch: 482, Train Loss: 0.6221\n",
      "Epoch: 483, Train Loss: 0.6222\n",
      "Epoch: 484, Train Loss: 0.6219\n",
      "Epoch: 485, Train Loss: 0.6218\n",
      "Epoch: 486, Train Loss: 0.6217\n",
      "Epoch: 487, Train Loss: 0.6216\n",
      "Epoch: 488, Train Loss: 0.6215\n",
      "Epoch: 489, Train Loss: 0.6213\n",
      "Epoch: 490, Train Loss: 0.6214\n",
      "Epoch: 491, Train Loss: 0.6211\n",
      "Epoch: 492, Train Loss: 0.6211\n",
      "Epoch: 493, Train Loss: 0.6210\n",
      "Epoch: 494, Train Loss: 0.6209\n",
      "Epoch: 495, Train Loss: 0.6209\n",
      "Epoch: 496, Train Loss: 0.6205\n",
      "Epoch: 497, Train Loss: 0.6207\n",
      "Epoch: 498, Train Loss: 0.6206\n",
      "Epoch: 499, Train Loss: 0.6202\n",
      "Epoch: 500, Train Loss: 0.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:06<00:00, 71.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 2024.23, Val Mean Reciprocal Rank: 0.09, Val Hits@10: 0.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20466/20466 [04:35<00:00, 74.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Rank: 2069.01, Test Mean Reciprocal Rank: 0.09, Test Hits@10: 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    epoch += 1 #for string printing\n",
    "    loss = train(train_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}')\n",
    "    train_metrics ={\n",
    "        \"train_epoch\": epoch-1, #fixes the index\n",
    "        \"train_loss\": loss\n",
    "    }\n",
    "    if epoch % 25 == 0:\n",
    "        loss, mean_rank, mrr, hits_at_10 = test(val_data)\n",
    "        print(f'Val Mean Rank: {mean_rank:.2f}, Val Mean Reciprocal Rank: {mrr:.2f}, Val Hits@10: {hits_at_10:.4f}')\n",
    "        val_metrics ={\n",
    "            \"val_loss\": loss,\n",
    "            \"val_mean_rank\": mean_rank,\n",
    "            \"val_mrr\": mrr,\n",
    "            \"val_hits_at_10\": hits_at_10\n",
    "        }\n",
    "    #log to wandb\n",
    "    wandb.log({**train_metrics, **val_metrics} if 'val_metrics' in locals() else {**train_metrics})\n",
    "\n",
    "#once everything is finished, test model\n",
    "loss, mean_rank, mrr, hits_at_10 = test(test_data)\n",
    "print(f'Test Mean Rank: {mean_rank:.2f}, Test Mean Reciprocal Rank: {mrr:.2f}, Test Hits@10: {hits_at_10:.4f}')\n",
    "test_metrics ={\n",
    "            \"test_loss\": loss,\n",
    "            \"test_mean_rank\": mean_rank,\n",
    "            \"test_mrr\": mrr,\n",
    "            \"test_hits_at_10\": hits_at_10\n",
    "        }\n",
    "wandb.log({**test_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_hits_at_10</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_mean_rank</td><td>▁</td></tr><tr><td>test_mrr</td><td>▁</td></tr><tr><td>train_epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_hits_at_10</td><td>▁▁▁▁▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>██▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mean_rank</td><td>██▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mrr</td><td>▁▁▁▁▂▂▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_hits_at_10</td><td>0.17385</td></tr><tr><td>test_loss</td><td>0.6314</td></tr><tr><td>test_mean_rank</td><td>2069.01172</td></tr><tr><td>test_mrr</td><td>0.09284</td></tr><tr><td>train_epoch</td><td>499</td></tr><tr><td>train_loss</td><td>0.62024</td></tr><tr><td>val_hits_at_10</td><td>0.17519</td></tr><tr><td>val_loss</td><td>0.63112</td></tr><tr><td>val_mean_rank</td><td>2024.2251</td></tr><tr><td>val_mrr</td><td>0.09036</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FB15k_237_RotatE_embedding_model 2024-02-27 03:11:04</strong> at: <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/yhrxb62j' target=\"_blank\">https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/yhrxb62j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240227_031104-yhrxb62j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = osp.join(os.getcwd(), f'{dataset_name}_embedding_model_weights.pth')\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "# Fetch a batch from your train_loader\n",
    "for batch in train_loader:\n",
    "    # Assuming batch contains head_index, rel_type, tail_index, and possibly other data\n",
    "    head_index, rel_type, tail_index = batch\n",
    "    break  # Only need one batch for this purpose\n",
    "\n",
    "# Use the fetched batch to provide dummy inputs for the export\n",
    "# Ensure these variables are moved to the same device as your model if necessary\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (head_index, rel_type, tail_index),  # Use actual data as dummy inputs\n",
    "    f'{dataset_name}_embedding_model_weights.onnx',\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=[\"head_index\", \"rel_type\", \"tail_index\"],  # Adjust input names as needed\n",
    "    dynamic_axes={\n",
    "        \"head_index\": {0: \"batch_size\"}, \n",
    "        \"rel_type\": {0: \"batch_size\"}, \n",
    "        \"tail_index\": {0: \"batch_size\"}\n",
    "    }\n",
    ")\n",
    "wandb.save(f'{dataset_name}_embedding_model_weights.onnx')\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScoreMatchingDiffKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
