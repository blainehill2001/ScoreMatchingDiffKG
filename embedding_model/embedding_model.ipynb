{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Blaine Hill\n",
    "\n",
    "In this notebook, we program out how to embed a KG such as FB15k_237 using RotatE. The weights are saved under embedding_model_weights.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbthill1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"embedding_model.ipynb\"\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from torch_geometric.nn import RotatE\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blaineh2/anaconda3/envs/ScoreMatchingDiffKG/lib/python3.9/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from torch_geometric.datasets import FB15k_237\n",
    "from torch_geometric.nn import ComplEx\n",
    "\n",
    "dataset_name='FB15k_237'\n",
    "embedding_model_name='RotatE'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = osp.join(os.getcwd(), '..', 'data', dataset_name)\n",
    "\n",
    "train_data = FB15k_237(path, split='train')[0].to(device)\n",
    "val_data = FB15k_237(path, split='val')[0].to(device)\n",
    "test_data = FB15k_237(path, split='test')[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/blaineh2/ScoreMatchingDiffKG/embedding_model/wandb/run-20240227_015821-o92lbjiq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/o92lbjiq' target=\"_blank\">FB15k_237_RotatE_embedding_model 2024-02-27 01:58:21</a></strong> to <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding' target=\"_blank\">https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/o92lbjiq' target=\"_blank\">https://wandb.ai/bthill1/ScoreMatchingDiffKG_Embedding/runs/o92lbjiq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=f\"ScoreMatchingDiffKG_Embedding\",\n",
    "    name=f\"{dataset_name}_{embedding_model_name}_embedding_model {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    config={\n",
    "        \"epochs\": 3,\n",
    "        \"batch_size\": 1000,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 1e-6,\n",
    "        \"k\": 10 #used for top-k evaluation\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RotatE(num_nodes=train_data.num_nodes, num_relations=train_data.num_edge_types, hidden_channels=50).to(device) \n",
    "\n",
    "wandb.watch(model) #tracks gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on FB15k dataset\n",
    "train_loader = model.loader(\n",
    "    head_index=train_data.edge_index[0],\n",
    "    rel_type=train_data.edge_type,\n",
    "    tail_index=train_data.edge_index[1],\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "# val_loader = model.loader(\n",
    "#     head_index=val_data.edge_index[0],\n",
    "#     rel_type=val_data.edge_type,\n",
    "#     tail_index=val_data.edge_index[1],\n",
    "#     batch_size=config.batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "# test_loader = model.loader(\n",
    "#     head_index=test_data.edge_index[0],\n",
    "#     rel_type=test_data.edge_type,\n",
    "#     tail_index=test_data.edge_index[1],\n",
    "#     batch_size=config.batch_size,\n",
    "#     shuffle=True,\n",
    "# )\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for head_index, rel_type, tail_index in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(head_index, rel_type, tail_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scale on specific number of elements in batch\n",
    "        total_loss += float(loss) * head_index.numel()\n",
    "        total_examples += head_index.numel()\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    # Calculate loss\n",
    "    loss = model.loss(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "    )\n",
    "    # Evaluate the model using model.test()\n",
    "    mean_rank, mrr, hits_at_k = model.test(\n",
    "        head_index=data.edge_index[0],\n",
    "        rel_type=data.edge_type,\n",
    "        tail_index=data.edge_index[1],\n",
    "        batch_size=config.batch_size,\n",
    "        k=config.k,\n",
    "    )\n",
    "    return loss, mean_rank, mrr, hits_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 0.7774\n",
      "Epoch: 002, Train Loss: 0.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17535/17535 [04:04<00:00, 71.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Mean Rank: 9269.36, Val Mean Reciprocal Rank: 0.00, Val Hits@10: 0.0001\n",
      "Epoch: 003, Train Loss: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20466/20466 [04:43<00:00, 72.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Rank: 8993.22, Test Mean Reciprocal Rank: 0.00, Test Hits@10: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.epochs):\n",
    "    epoch += 1 #for string printing\n",
    "    loss = train(train_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {loss:.4f}')\n",
    "    train_metrics ={\n",
    "        \"train_epoch\": epoch-1, #fixes the index\n",
    "        \"train_loss\": loss\n",
    "    }\n",
    "    if epoch % 2 == 0:\n",
    "        loss, mean_rank, mrr, hits_at_10 = test(val_data)\n",
    "        print(f'Val Mean Rank: {mean_rank:.2f}, Val Mean Reciprocal Rank: {mrr:.2f}, Val Hits@10: {hits_at_10:.4f}')\n",
    "        val_metrics ={\n",
    "            \"val_loss\": loss,\n",
    "            \"val_mean_rank\": mean_rank,\n",
    "            \"val_mrr\": mrr,\n",
    "            \"val_hits_at_10\": hits_at_10\n",
    "        }\n",
    "    #log to wandb\n",
    "    wandb.log({**train_metrics, **val_metrics} if 'val_metrics' in locals() else {**train_metrics})\n",
    "\n",
    "#once everything is finished, test model\n",
    "loss, mean_rank, mrr, hits_at_10 = test(test_data)\n",
    "print(f'Test Mean Rank: {mean_rank:.2f}, Test Mean Reciprocal Rank: {mrr:.2f}, Test Hits@10: {hits_at_10:.4f}')\n",
    "test_metrics ={\n",
    "            \"test_loss\": loss,\n",
    "            \"test_mean_rank\": mean_rank,\n",
    "            \"test_mrr\": mrr,\n",
    "            \"test_hits_at_10\": hits_at_10\n",
    "        }\n",
    "wandb.log({**test_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RotatE' object has no attribute 'to_onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_embedding_model_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), path)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_onnx\u001b[49m()\n\u001b[1;32m      5\u001b[0m wandb\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_embedding_model_weights.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ScoreMatchingDiffKG/lib/python3.9/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RotatE' object has no attribute 'to_onnx'"
     ]
    }
   ],
   "source": [
    "path = osp.join(os.getcwd(), f'{dataset_name}_embedding_model_weights.pth')\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "model.to_onnx()\n",
    "wandb.save(f'{dataset_name}_embedding_model_weights.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScoreMatchingDiffKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
